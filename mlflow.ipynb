{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import MLflow libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Set Server Uri**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create new experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='Used Car Price Prediction', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new experiment\n",
    "mlflow.create_experiment(\"Used Car Price Prediction\")\n",
    "#use the experiment created\n",
    "mlflow.set_experiment(\"Used Car Price Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load the dataset and devide it into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the dataset in pandas dataframe and apply the Label encoder and the One hot encoder for the categorical data\n",
    "it should be noted that this dataset is the cleaned dataset after applying all the preprocessing steps presented \n",
    "in the file preprocessing.py \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "data=pd.read_csv('car_price.csv')\n",
    "name=pd.get_dummies(data['name'])\n",
    "fuel = pd.get_dummies(data['fuel'])\n",
    "transmission = pd.get_dummies(data['transmission'])\n",
    "owner = data['owner'].map(lambda x: 1 if x=='First  Owner' else 2 if x=='Second  Owner' else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the features and the target column\n",
    "features = pd.concat ([name ,fuel ,transmission ,owner ,data.drop(['name','transmission','fuel','owner','selling_price'],axis =1)],axis =1)\n",
    "target = data['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devide the dataframe into train and test\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train ,X_test ,y_train ,y_test=train_test_split(features ,target ,test_size=0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MLflow Tracking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the metircs used to evaluate each model \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Defining model parameters\n",
    "normalize = True\n",
    "# Running MLFlow script\n",
    "with mlflow.start_run(run_name=\"Linear Regression run_1\"):\n",
    "# Instantiating model with model parameters\n",
    "    model = LinearRegression (normalize= normalize  )\n",
    "# Fitting training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "# Running prediction on validation dataset\n",
    "    preds = model.predict(X_test)\n",
    "# Getting metrics on the validation dataset\n",
    "    rmse = mean_squared_error(preds, y_test)\n",
    "    abs_error = mean_absolute_error(preds, y_test)\n",
    "    r2 = r2_score(preds, y_test)\n",
    "# Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('normalize', normalize)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mlflow.log_metric('abs_error', abs_error)\n",
    "    mlflow.log_metric('r2', r2)\n",
    "# Logging model to MLFlow\n",
    "    mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the metircs used to evaluate each model \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Defining model parameters\n",
    "normalize = False\n",
    "# Running MLFlow script\n",
    "with mlflow.start_run(run_name=\"Linear Regression run_2\"):\n",
    "# Instantiating model with model parameters\n",
    "    model = LinearRegression (normalize= normalize  )\n",
    "# Fitting training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "# Running prediction on validation dataset\n",
    "    preds = model.predict(X_test)\n",
    "# Getting metrics on the validation dataset\n",
    "    rmse = mean_squared_error(preds, y_test)\n",
    "    abs_error = mean_absolute_error(preds, y_test)\n",
    "    r2 = r2_score(preds, y_test)\n",
    "# Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('normalize', normalize)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mlflow.log_metric('abs_error', abs_error)\n",
    "    mlflow.log_metric('r2', r2)\n",
    "# Logging model to MLFlow\n",
    "    mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Defining model parameters\n",
    "criterion = 'mse'\n",
    "n_estimators = 30\n",
    "# Running MLFlow script\n",
    "with mlflow.start_run():\n",
    "# Instantiating model with model parameters\n",
    "    model = RandomForestRegressor(criterion=  criterion,\n",
    "                       n_estimators= n_estimators)\n",
    "# Fitting training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "# Running prediction on validation dataset\n",
    "    preds = model.predict(X_test)\n",
    "# Getting metrics on the validation dataset\n",
    "    rmse = mean_squared_error(preds, y_test)\n",
    "    abs_error = mean_absolute_error(preds, y_test)\n",
    "    r2 = r2_score(preds, y_test)\n",
    "# Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('criterion', criterion)\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mlflow.log_metric('abs_error', abs_error)\n",
    "    mlflow.log_metric('r2', r2)\n",
    "# Logging model to MLFlow\n",
    "    mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Defining model parameters\n",
    "criterion = 'mse'\n",
    "n_estimators = 20\n",
    "# Running MLFlow script\n",
    "with mlflow.start_run():\n",
    "# Instantiating model with model parameters\n",
    "    model = RandomForestRegressor(criterion=  criterion,\n",
    "                       n_estimators= n_estimators)\n",
    "# Fitting training data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "# Running prediction on validation dataset\n",
    "    preds = model.predict(X_test)\n",
    "# Getting metrics on the validation dataset\n",
    "    rmse = mean_squared_error(preds, y_test)\n",
    "    abs_error = mean_absolute_error(preds, y_test)\n",
    "    r2 = r2_score(preds, y_test)\n",
    "# Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('criterion', criterion)\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mlflow.log_metric('abs_error', abs_error)\n",
    "    mlflow.log_metric('r2', r2)\n",
    "# Logging model to MLFlow\n",
    "    mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MLflow Model Registry**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get the run_id for the highest score run (Based on R2 metric)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the run_id that have the highest score is : 212d1bcfb3b843aa80c7bce94c892555\n"
     ]
    }
   ],
   "source": [
    "#Load all the run_ids bellongs to the experiment_id=1 refers to the Used car price prediction experiment\n",
    "run_id=mlflow.search_runs(experiment_ids=\"1\")\n",
    "#sort all the run_ids in descending order based on the metric R2 for each run\n",
    "run_id.sort_values(['metrics.r2'],ascending=False,inplace=True)\n",
    "#save the fisrt run_id which refer to the run that have the highest score\n",
    "run_id_best = run_id.head(1)[\"run_id\"].values[0]\n",
    "print(f\"the run_id that have the highest score is : {run_id_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Register the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegisteredModel: creation_timestamp=1642954689098, description='', last_updated_timestamp=1642954689098, latest_versions=[], name='Used Car Price Prediction', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new model named Used Car Price Prediction \n",
    "# It should be notice that new registered model requires a unique name \n",
    "client = MlflowClient()\n",
    "client.create_registered_model(\"Used Car Price Prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/01/23 17:18:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Used Car Price Prediction, version 1\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "result = client.create_model_version(\n",
    "    name=\"Used Car Price Prediction\",\n",
    "    source=f\"mlruns/1/{run_id_best}/artifacts/model\",\n",
    "    run_id=run_id_best\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transition modele stage from none to Staging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1642954717096, current_stage='Staging', description='', last_updated_timestamp=1642954734840, name='Used Car Price Prediction', run_id='212d1bcfb3b843aa80c7bce94c892555', run_link='', source='mlruns/1/212d1bcfb3b843aa80c7bce94c892555/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"Used Car Price Prediction\",\n",
    "    version=1,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transition modele stage from Staging to Production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1642954717096, current_stage='Production', description='', last_updated_timestamp=1642954742163, name='Used Car Price Prediction', run_id='212d1bcfb3b843aa80c7bce94c892555', run_link='', source='mlruns/1/212d1bcfb3b843aa80c7bce94c892555/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"Used Car Price Prediction\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function take as parameter all the features required to make prediction\n",
    "and return dataframe with one row and 32 columns which is the number of\n",
    "features to make prediction\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "def predict_price(name,transmission,fuel,owner,year,km_driven,engine,max_power):\n",
    "    x = []\n",
    "    x[:26] = np.zeros(32,dtype='int32')\n",
    "    x[27] = owner\n",
    "    x[28] = year\n",
    "    x[29] = km_driven\n",
    "    x[30] = engine\n",
    "    x[31] = max_power\n",
    "    \n",
    "    name_index = np.where(features.columns==name)[0][0]\n",
    "    transmission_index = np.where(features.columns==transmission)[0][0]\n",
    "    fuel_index = np.where(features.columns==fuel)[0][0]\n",
    "    \n",
    "    if name_index>=0:\n",
    "        x[name_index] = 1\n",
    "    if transmission_index>=0:\n",
    "        x[transmission_index] = 1\n",
    "    if fuel_index>=2:\n",
    "        x[fuel_index] = 1\n",
    "        \n",
    "    return pd.DataFrame(x).transpose()\n",
    "\n",
    "test = predict_price('Audi','Manual','Petrol',1,2011,15000,2050,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the price predicted is : 1786433.3333333333\n"
     ]
    }
   ],
   "source": [
    "prediction1 = predict_price('Audi','Manual','Petrol',1,2011,15000,2050,150)\n",
    "import mlflow.pyfunc\n",
    "model_name = \"Used Car Price Prediction\"\n",
    "stage = 'Production'\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "print(f'the price predicted is : {model.predict(prediction1)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849766.6666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2 = predict_price('Audi','Automatic','Petrol',2,2011,15000,2050,150)\n",
    "import mlflow.pyfunc\n",
    "model_name = \"Used Car Price Prediction\"\n",
    "stage = 'Production'\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "model.predict(prediction2)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b219562547d110e96c85cf728026ec61107a3efad87266f11386bb40ecd5dea4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
